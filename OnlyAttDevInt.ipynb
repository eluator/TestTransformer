{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "49703b47-2b07-44a9-9d08-53836a5e6515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "True\n",
      "2.4.0+cu121\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from dataclasses import dataclass\n",
    "import einops\n",
    "from einops import einsum\n",
    "import math\n",
    "from easy_transformer.utils import get_corner, gelu_new, tokenize_and_concatenate\n",
    "from easy_transformer import EasyTransformer\n",
    "import pandas as pd\n",
    "import json\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from copy import deepcopy\n",
    "from bisect import bisect_right\n",
    "from datasets import load_dataset, load_dataset_builder\n",
    "\n",
    "from TransformerModule import DemoTransformer, AttentionOnly\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "44a1ad7b-bfe9-40ce-8125-f16f575d8589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConfigOnlyAt(d_model=10, debug=False, layer_norm_eps=1e-05, d_vocab=50257, init_range=0.02, n_ctx=47, d_head=10, d_mlp=10, n_heads=2, n_layers=2)\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class ConfigOnlyAt:\n",
    "    d_model: int = 10 # 256\n",
    "    debug: bool = False\n",
    "    layer_norm_eps: float = 1e-5\n",
    "    d_vocab: int = 50257\n",
    "    init_range: float = 0.02\n",
    "    n_ctx: int = 47 #1024\n",
    "    d_head: int = 10 # 64\n",
    "    d_mlp: int = 10 # 3072\n",
    "    n_heads: int = 2 # 8\n",
    "    n_layers: int = 2\n",
    "\n",
    "cfg = ConfigOnlyAt()\n",
    "print(cfg)\n",
    "\n",
    "class LiTransformer(L.LightningModule):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.transformer = DemoTransformer(cfg)\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        context_window, target_window = batch\n",
    "        context_window, target_window = context_window.to(device), target_window.to(device)\n",
    "        logits = self.transformer(context_window)\n",
    "        logits = einops.rearrange(logits, \"batch position vocabulary -> batch vocabulary position\")\n",
    "        loss = self.criterion(logits, target_window)\n",
    "        \n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        context_window, target_window = batch\n",
    "        context_window, target_window = context_window.to(device), target_window.to(device)\n",
    "        logits = self.transformer(context_window)\n",
    "        logits = einops.rearrange(logits, \"batch position vocabulary -> batch vocabulary position\")\n",
    "        loss = self.criterion(logits, target_window)\n",
    "        \n",
    "        # Logging to TensorBoard (if installed) by default\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "firstTranformer = LiTransformer(cfg).to(device)\n",
    "firstTranformer.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8408358-5210-475e-aff8-2cb3cb7f91b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cpu\n",
      "Finished loading pretrained model gpt2-small into EasyTransformer!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' I'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_gpt2 = EasyTransformer.from_pretrained(\"gpt2-small\", fold_ln=False, center_unembed=False, center_writing_weights=False, device = 'cpu')\n",
    "reference_text = \"I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world!\"\n",
    "tokens = reference_gpt2.to_tokens(reference_text)\n",
    "target_tokens = torch.cat((tokens[0][1:], torch.tensor([50256])), 0).view(1, -1)\n",
    "logits, cache = reference_gpt2.run_with_cache(reference_text)\n",
    "log_probs = logits.log_softmax(dim=-1)\n",
    "probs = logits.log_softmax(dim=-1)\n",
    "reference_gpt2.tokenizer.batch_decode(logits.argmax(dim=-1)[0])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9b4bba4-5e9a-41a6-a1a4-546d105214db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1288 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "      <th>metadata</th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alsatian Cheese Tart\\n\\nFrench Chef Michel Ber...</td>\n",
       "      <td>{'pile_set_name': ['Pile-CC', 'OpenWebText2']}</td>\n",
       "      <td>21</td>\n",
       "      <td>[tensor(50256), tensor(2348), tensor(49720), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>depicted by four young winged men in Roman-lik...</td>\n",
       "      <td>{'pile_set_name': ['Wikipedia (en)', 'Pile-CC']}</td>\n",
       "      <td>81</td>\n",
       "      <td>[tensor(50256), tensor(10378), tensor(5722), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Available in:\\n\\ndescription\\n\\nOn Tuesday Mar...</td>\n",
       "      <td>{'pile_set_name': ['Pile-CC', 'Pile-CC']}</td>\n",
       "      <td>102</td>\n",
       "      <td>[tensor(50256), tensor(10493), tensor(287), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Date:\\n\\nDiscipline:\\n\\nSource:\\n\\nProduct num...</td>\n",
       "      <td>{'pile_set_name': ['Pile-CC', 'Pile-CC']}</td>\n",
       "      <td>107</td>\n",
       "      <td>[tensor(50256), tensor(10430), tensor(25), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other meetings she had chaired. Stockholders w...</td>\n",
       "      <td>{'pile_set_name': ['Pile-CC', 'Pile-CC']}</td>\n",
       "      <td>110</td>\n",
       "      <td>[tensor(50256), tensor(847), tensor(8292), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>wedding day and itinerary runs without a hitch...</td>\n",
       "      <td>{'pile_set_name': ['Pile-CC', 'USPTO Backgroun...</td>\n",
       "      <td>34118665</td>\n",
       "      <td>[tensor(50256), tensor(86), tensor(6048), tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>a faster motor. Motor speed is already a param...</td>\n",
       "      <td>{'pile_set_name': ['USPTO Backgrounds', 'Pile-...</td>\n",
       "      <td>34118691</td>\n",
       "      <td>[tensor(50256), tensor(64), tensor(5443), tens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>Flag Law on 29 May 1936.\\n\\nFlag of Turkey\\n\\n...</td>\n",
       "      <td>{'pile_set_name': ['Pile-CC', 'OpenWebText2']}</td>\n",
       "      <td>34118794</td>\n",
       "      <td>[tensor(50256), tensor(34227), tensor(3854), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>president; he should, at best, be reviving cel...</td>\n",
       "      <td>{'pile_set_name': ['OpenWebText2', 'Pile-CC']}</td>\n",
       "      <td>34118819</td>\n",
       "      <td>[tensor(50256), tensor(22540), tensor(26), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>newly rebuilt temple after the return from the...</td>\n",
       "      <td>{'pile_set_name': ['Pile-CC', 'Pile-CC']}</td>\n",
       "      <td>34118866</td>\n",
       "      <td>[tensor(50256), tensor(3605), tensor(306), ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 contents  \\\n",
       "0       Alsatian Cheese Tart\\n\\nFrench Chef Michel Ber...   \n",
       "1       depicted by four young winged men in Roman-lik...   \n",
       "2       Available in:\\n\\ndescription\\n\\nOn Tuesday Mar...   \n",
       "3       Date:\\n\\nDiscipline:\\n\\nSource:\\n\\nProduct num...   \n",
       "4       other meetings she had chaired. Stockholders w...   \n",
       "...                                                   ...   \n",
       "999995  wedding day and itinerary runs without a hitch...   \n",
       "999996  a faster motor. Motor speed is already a param...   \n",
       "999997  Flag Law on 29 May 1936.\\n\\nFlag of Turkey\\n\\n...   \n",
       "999998  president; he should, at best, be reviving cel...   \n",
       "999999  newly rebuilt temple after the return from the...   \n",
       "\n",
       "                                                 metadata        id  \\\n",
       "0          {'pile_set_name': ['Pile-CC', 'OpenWebText2']}        21   \n",
       "1        {'pile_set_name': ['Wikipedia (en)', 'Pile-CC']}        81   \n",
       "2               {'pile_set_name': ['Pile-CC', 'Pile-CC']}       102   \n",
       "3               {'pile_set_name': ['Pile-CC', 'Pile-CC']}       107   \n",
       "4               {'pile_set_name': ['Pile-CC', 'Pile-CC']}       110   \n",
       "...                                                   ...       ...   \n",
       "999995  {'pile_set_name': ['Pile-CC', 'USPTO Backgroun...  34118665   \n",
       "999996  {'pile_set_name': ['USPTO Backgrounds', 'Pile-...  34118691   \n",
       "999997     {'pile_set_name': ['Pile-CC', 'OpenWebText2']}  34118794   \n",
       "999998     {'pile_set_name': ['OpenWebText2', 'Pile-CC']}  34118819   \n",
       "999999          {'pile_set_name': ['Pile-CC', 'Pile-CC']}  34118866   \n",
       "\n",
       "                                                   tokens  \n",
       "0       [tensor(50256), tensor(2348), tensor(49720), t...  \n",
       "1       [tensor(50256), tensor(10378), tensor(5722), t...  \n",
       "2       [tensor(50256), tensor(10493), tensor(287), te...  \n",
       "3       [tensor(50256), tensor(10430), tensor(25), ten...  \n",
       "4       [tensor(50256), tensor(847), tensor(8292), ten...  \n",
       "...                                                   ...  \n",
       "999995  [tensor(50256), tensor(86), tensor(6048), tens...  \n",
       "999996  [tensor(50256), tensor(64), tensor(5443), tens...  \n",
       "999997  [tensor(50256), tensor(34227), tensor(3854), t...  \n",
       "999998  [tensor(50256), tensor(22540), tensor(26), ten...  \n",
       "999999  [tensor(50256), tensor(3605), tensor(306), ten...  \n",
       "\n",
       "[1000000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('../../data/train_1M.jsonl', lines=True)\n",
    "data.insert(3, \"tokens\", [reference_gpt2.to_tokens(data.contents[i])[0] for i, x in enumerate(data.contents)], True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11e0e387-bb5c-47af-9025-364f94677cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.tokens.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56c68c82-f5f9-45a7-8f2a-03761eab32ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"depicted by four young winged men in Roman-like dresses, driving vessels and blowing air into horns. The central upper square is an old man representing the Year, with the Wheel of Time, while at the upper corners are the personifications of the Rivers of Paradise. The other six upper squares depict the Four Seasons, as well as Samson and Abel (or Cain).\\n\\nThe two lower corners show the personifications of the Sun (left, symbolizing Sunday) and the Moon (right, much deteriorated, symbolizing Monday), while the  side outer squares represent the months (only eight of which survive). At the bottom are incomplete scenes of the discovery of Holy Cross.\\n\\nSources\\n\\nExternal links\\n\\nOfficial cathedral's website \\nPage with details of the figures \\nPage with links to websites and the newest literature  (2012)Publication Date:\\n\\nDiscipline:\\n\\nSource:\\n\\nProduct number:\\n\\nLength:\\n\\nAlso Available in:\\n\\ndescription\\n\\nIn October 2004 Fernández Pujals, founder of Telepizza, an international home delivery pizza business, bought 24.9% of Jazztel (€90 million), a telecom company. At the time, Jazztel that was near bankruptcy and needed a capital injection to finish the year. Over the next ten years, Fernández Pujals led the restructuring of Jazztel's debt, reached an agreement with the former monopoly Telefónica, set up internal call centers, and transformed Jazztel into the fastest growing broadband operator in Spain. The case describes how Fernández Pujals designed and managed the board and led Jazztel towards profitable growth.\\n\\nlearning objective:\\n\\nThe case provides an example of board dynamics and corporate governance of a Spanish telecom company with a controlling shareholder serving as Chairman of the Board of Directors.\\n\\nPublication Date:\\n\\nDiscipline:\\n\\nSource:\\n\\nProduct number:\\n\\nLength:\\n\\nAlso\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.contents.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cfa748f8-0c8c-41fa-a14a-a2ea59b47b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGPTDataset(Dataset):\n",
    "    def __init__(self, data, sequence_length):\n",
    "        self.data = data\n",
    "        self.sequence_length = sequence_length\n",
    "        self.n_samples = len(self.data)\n",
    "        self.li = [len(tokens) for tokens in self.data.tokens.values]\n",
    "        self.cumulative_li = deepcopy(self.li)\n",
    "        self.cumulative_li[0] += - self.sequence_length \n",
    "        for i in range(1, len(self.cumulative_li)):\n",
    "            self.cumulative_li[i] = self.cumulative_li[i-1] + self.cumulative_li[i] - self.sequence_length\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.cumulative_li[-1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        string_i = bisect_right(self.cumulative_li, idx)\n",
    "        diff = self.cumulative_li[string_i] - idx\n",
    "        context_window = self.data.tokens.values[string_i][-diff-self.sequence_length:-diff]\n",
    "        if diff == 1:\n",
    "            target_window = torch.cat((self.data.tokens.values[string_i][-diff-self.sequence_length+1:-diff], torch.tensor([50256])), 0)\n",
    "        else:\n",
    "            target_window = self.data.tokens.values[string_i][-diff-self.sequence_length+1:-diff+1]\n",
    "        return context_window, target_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5e723565-b474-4494-848d-f4dd87d4ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = CustomGPTDataset(data, sequence_length = 47)\n",
    "min(training_data.li), max(training_data.li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "755a32a1-8c63-4ca2-906e-70e31cb8e8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = utils.data.DataLoader(training_data, batch_size=64, shuffle=False, pin_memory = False)\n",
    "len(next(iter(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e64e16fe-21cb-46e1-a67a-0cc48294c286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/eluator/AI_Safety/lib/python3.12/site-packages/lightning/pytorch/trainer/configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | transformer | DemoTransformer  | 1.1 M  | train\n",
      "1 | criterion   | CrossEntropyLoss | 0      | train\n",
      "---------------------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.233     Total estimated model params size (MB)\n",
      "17        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846f7727362c4c3bbc2e562de6bc22fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "# train the model (hint: here are some helpful Trainer arguments for rapid idea iteration)\n",
    "trainer = L.Trainer(limit_train_batches=100, max_epochs=1)\n",
    "trainer.fit(model=firstTranformer, train_dataloaders=train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7fcdae8e-cd81-4240-9d00-e8c06cede63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76cb3a5b4a314686a981d3baa1dc3b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/AI_Safety/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/AI_Safety/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:679\u001b[0m, in \u001b[0;36mTrainer._validate_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    676\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn, ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    678\u001b[0m )\n\u001b[0;32m--> 679\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;66;03m# remove the tensors from the validation results\u001b[39;00m\n",
      "File \u001b[0;32m~/AI_Safety/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/AI_Safety/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:1018\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluating:\n\u001b[0;32m-> 1018\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n",
      "File \u001b[0;32m~/AI_Safety/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py:178\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI_Safety/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py:135\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n",
      "File \u001b[0;32m~/AI_Safety/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py:396\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    391\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    395\u001b[0m )\n\u001b[0;32m--> 396\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n",
      "File \u001b[0;32m~/AI_Safety/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:319\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 319\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/AI_Safety/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py:411\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[105], line 39\u001b[0m, in \u001b[0;36mLiTransformer.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     38\u001b[0m context_window, target_window \u001b[38;5;241m=\u001b[39m context_window\u001b[38;5;241m.\u001b[39mto(device), target_window\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 39\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_window\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m logits \u001b[38;5;241m=\u001b[39m einops\u001b[38;5;241m.\u001b[39mrearrange(logits, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch position vocabulary -> batch vocabulary position\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/AI_Safety/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI_Safety/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/AI_Safety/TestTransformer/TransformerModule.py:235\u001b[0m, in \u001b[0;36mDemoTransformer.forward\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 235\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m normalized_resid_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_final(residual)\n",
      "File \u001b[0;32m~/AI_Safety/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI_Safety/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/AI_Safety/TestTransformer/TransformerModule.py:211\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre)\u001b[0m\n\u001b[1;32m    210\u001b[0m normalized_resid_pre \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1(resid_pre)\n\u001b[0;32m--> 211\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_resid_pre\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m resid_mid \u001b[38;5;241m=\u001b[39m resid_pre \u001b[38;5;241m+\u001b[39m attn_out\n",
      "File \u001b[0;32m~/AI_Safety/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI_Safety/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/AI_Safety/TestTransformer/TransformerModule.py:134\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, normalized_resid_pre)\u001b[0m\n\u001b[1;32m    133\u001b[0m attn_scores \u001b[38;5;241m=\u001b[39m qk \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39md_head)\n\u001b[0;32m--> 134\u001b[0m attn_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_causal_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_scores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m pattern \u001b[38;5;241m=\u001b[39m attn_scores\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# [batch, n_heads, query_pos, key_pos]\u001b[39;00m\n",
      "File \u001b[0;32m~/AI_Safety/TestTransformer/TransformerModule.py:143\u001b[0m, in \u001b[0;36mAttention.apply_causal_mask\u001b[0;34m(self, attn_scores)\u001b[0m\n\u001b[1;32m    142\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtriu(torch\u001b[38;5;241m.\u001b[39mones(attn_scores\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m), attn_scores\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), device\u001b[38;5;241m=\u001b[39mattn_scores\u001b[38;5;241m.\u001b[39mdevice), diagonal\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mbool()\n\u001b[0;32m--> 143\u001b[0m \u001b[43mattn_scores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIGNORE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_scores\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m firstTranformer \u001b[38;5;241m=\u001b[39m firstTranformer\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(firstTranformer\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirstTranformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI_Safety/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:639\u001b[0m, in \u001b[0;36mTrainer.validate\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI_Safety/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "firstTranformer = firstTranformer.to(device)\n",
    "print(firstTranformer.device)\n",
    "trainer.validate(firstTranformer, dataloaders = train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68b0e275-c2b5-496d-b4a5-bd5591b4768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = rand_float_test(LayerNorm, [2, 4, 768])\n",
    "# _ = load_gpt2_test(LayerNorm, reference_gpt2.ln_final, \"blocks.11.hook_resid_post\")\n",
    "# rand_int_test(Embed, [2, 4])\n",
    "# load_gpt2_test(Embed, reference_gpt2.embed, tokens)\n",
    "# rand_int_test(PosEmbed, [2, 4])\n",
    "# load_gpt2_test(PosEmbed, reference_gpt2.pos_embed, tokens)\n",
    "# rand_float_test(Attention, [2, 4, 768])\n",
    "# load_gpt2_test(Attention, reference_gpt2.blocks[0].attn, cache[\"blocks.0.ln1.hook_normalized\"])\n",
    "# rand_float_test(MLP, [2, 4, 768])\n",
    "# load_gpt2_test(MLP, reference_gpt2.blocks[0].mlp, cache[\"blocks.0.ln2.hook_normalized\"])\n",
    "# rand_float_test(Unembed, [2, 4, 768])\n",
    "# load_gpt2_test(Unembed, reference_gpt2.unembed, cache[\"ln_final.hook_normalized\"])\n",
    "# rand_float_test(TransformerBlock, [2, 4, 768])\n",
    "# load_gpt2_test(TransformerBlock, reference_gpt2.blocks[0], cache[\"resid_pre\", 0])\n",
    "# rand_int_test(DemoTransformer, [2, 4])\n",
    "# load_gpt2_test(DemoTransformer, reference_gpt2, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfc7f68-fbe5-44e4-9fbd-b6ba15e2955d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Safety",
   "language": "python",
   "name": "ai_safety"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
